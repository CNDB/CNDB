Common Node Database
====================

For community wireless networks (CWNs), a node database serves as a central
repository of network information. It comprises information about
nodes deployed at certain locations, devices installed at these
locations, information about internet addresses, and --- in networks that
use explicit link planning --- links among devices. All this information
is maintained via a web or REST interface by the community members.

During the last reporting period work on a `Common API`_ continued.
An application that already uses the prototype of this API, the
`Dashboard`_ is intended to display all information a user needs and
allow easy maintenance of node information. It integrates both static
information (node and device data, IP allocation) and dynamic
performance data. It will probably be integrated with our `Statistics
Server`_.

The `Statistics Server`_ and the `Spider`_ collect data from a running
network. The data is interesting for researchers to get new insights
into a running mesh network. In addition the `Spider`_ data is used when
importing the old Funkfeuer redeemer database into the NodeDB.

Currently we offer node configuration data from Funkfeuer Vienna and
Guifi.net in two NodeDB databases for research purposes. To import this
data, `Conversion and Import`_ routines had to be written, we outline
the problem encountered and lessons learned.

Finally for supporting IP address reservation (and IP address objects in
a relational database) and to address some requirements of the new
common API we had to `Improve the relational database back-end`_
which now supports new query mechanisms and database back-end-specific
data types.

Common API
----------

For accessing the common node database an Application programming
interface (API) was improved compared to the last report.

The API, which uses a `REpresentational State Transfer API`_ (REST API)
has been extended to support IP address reservation and will serve as a
basis for defining a common API.

.. _`REpresentational State Transfer API`:
    http://en.wikipedia.org/wiki/Representational_state_transfer

Dashboard
---------

Implementation of a user-dashboard started. The dashboard serves both
as a general web-app for interactions of end-users with the nodeDB as
well as a reference implementation, showcasing how the nodeDB can be
used for rich single-page web applications.

The Dashboard is built on top of the backbone.js library --- a
single-page application MVC framework written in javascript --- and
bootstrap --- a basic css library popularized by twitter. It thus demonstrates
how the nodeDB can be integrated with state-of-the art web
technologies.

Several challenges in querying the nodeDB became apparent while
developing the dashboard --- this helped to improve the use and test
cases for the nodedb and triggered a change of the sql interfacing
back-end to allow certain queries.

The dashboard is in a functional prototype stage right now and is
expected to be finished once the nodeDB is ready to be used and
contains all authentication and security features needed.

Authorization
--------------

In addition to password-based authentication, two new authentication
mechanisms were implemented.

Most browsers today support a method of secure --- if not very
user-friendly --- generation of client certificates where the secret key
stays with the browser. Since no python implementation for using this
mechanism on the server-side (although it exists since Netscape times)
was available we wrote a library to support the server-side of using
client certificates, the library pyspkac [pyspkac]_.

For use by clients of the `Common API`_ the framework was extended to
support ``REST authentication tokens``, aka ``RAT``. To get such a token, a
client sends a post-request with username and password to the RAT resource
and gets back an authentication token that can be used for a limited time to
authenticate subsequent requests.

The dashboard currently uses REST authentication tokens for authentication.

Statistics Server
-----------------

We started to implement a statistics server, collecting statistics from
the FunkFeuer network. The collected statistics (reachability, routing
and topology of the mesh network) help researchers to better understand
real-life mesh-networks.

The implementation of the statistics server triggered a privacy and
anonymization discussion in the FunkFeuer network that prompted us to
work on IP address anonymization. One promising approach was the
CryptoPAn [cryptopan]_ algorithm.

To integrate the Crypto-PAn algorithm in our software we created a
python module: pycryptopan [pycryptopan]_. The module is published with
the python package repository and available for python versions 2 and 3.


Conversion and Import
---------------------

For populating the node database, importers have been written to import
data from other sources into the node database.

To eventually switch over from the current Funkfeuer Vienna Node
database "Redeemer", an import for redeemer has been written. It converts
user data, node and device information as well as IP address
assignments. Since the current Redeemer database doesn't contain enough
information for the new database --- notably information about wireless
interface configuration is missing and it is unclear which interfaces
that have an IP address assigned belong to which device --- we also rely
on OLSR data and data retrieved by a spider (see section `Spider`_) to
complement the data in the redeemer database.

For data of Funkfeuer Graz, an importer was started which has not been
finished. It uses some of the same libraries for reading SQL dumps and
contributed to our `Lessons learned from importers`_.

To make the Redeemer data publicly available for research purposes an
anonymization option was added to not import the personal information
during database import.

In addition to the Vienna Redeemer database, an importer for a subset of
the Node data of guifi.net was written.

Both the anonymized data from Funkfeuer Vienna and a subset of
guifi.net data were made available for research purposes [nodedb13]_.

To facilitate updates, an account migration [account]_ feature was
implemented that can port the database accounts to the new database when
new data is imported.

Lessons learned from importers
++++++++++++++++++++++++++++++

For importing from another database, we used the SQL dump of that
database. This resulted in a library, part of [rsclib]_, that can read
SQL dumps (from both PostgreSQL and mySQL) and offer the data via a
python API.

When writing importers --- for both, CNML data from guifi.net [guifi1]_
as well as SQL database dumps for Funkfeuer Vienna and Graz --- we
encountered problems with the data offered. In particular, non-sanitized
data (like invalid MAC Addresses) and problems with character encodings.

The problems with character encodings were due to the long usage period
of the data in question which had encountered changes of character set
(from latin1 to Unicode based encodings like utf-8). Some data was
double-encoded. This resulted in a module for the SQL dump reader in
[rsclib]_ to sanitize the encoding problems.

Another problem when running our importers was the time it took to
complete the data import. This was traced to large transactions of the
underlying SQL database. Some commit statements at appropriate places in
the code improved performance drastically [tanzer13]_.  So an advice
when writing converters or importers boils down to:

    *Don't create all objects in a single transaction; commit every now
    and then.* [tanzer13]_

Spider
------

Originally intended for augmenting the data used by the importer (see
`Conversion and Import`_), a spider was written that extracts the
following information from the web-interfaces of the nodes in the
Funkfeuer network in Vienna:

- Version and type of software used

- WLAN configuration (if available)

- Network interfaces and configuration information

- IP Address information

The spider can be used on any network that uses OLSR for routing ---
currently the spider relies on the OLSR topology data for finding out
from which IP addresses to retrieve data.

Funkfeuer currently uses a mix of different hardware and software
components. The spider can currently handle the following software on
devices:

- Freifunk Firmware

- Backfire Vienna

- OpenWRT Firmware

- OLSR "Textinfo" Plugin output

The type of firmware running on the device is auto-detected. When
testing, the software auto-detected many nodes from the Funkfeuer Graz
network (which uses a different set of devices from Funkfeuer Vienna).

We currently spider the network once a day and keep the data retrieved
for statistics on network parameters. Some of the data will be made
available via our `Statistics Server`_.

Improve the relational database back-end
----------------------------------------

The [tapyr]_ framework uses `SQLAlchemy`_ to access relational
databases.

.. _`SQLAlchemy`: http://www.sqlalchemy.org/

During the development of the common node database, we identified some
weaknesses of Tapyr's SQLAlchemy wrapper. We implemented the improvements:

* Use of database-specific data types for database columns.

  Tapyr now supports the use of RDBM-specific data-types.

  For managing IP addresses with properties like network mask and
  ``contains`` relationship we had to extend the tapyr framework [tapyr]_ to
  support IP network operations. One of the back-end databases (PostgreSQL)
  native support IP address objects while other databases don't. The
  framework can now use the native IP address type if supported by the
  database and emulate the behavior for the other back-ends.

  The back-ends for both PostgreSQL and SQLite support the same queries, with
  PostgreSQL doing most of the work for tapyr, while
  the SQLite back-end implements IP address comparison with complex SQL
  expressions over the synthetic columns.

* Transitive queries of attributes of joined tables.

  Tapyr now supports the definition of query attributes that resolve to a SQL
  join of multiple tables.

  For the common node database, the most important use for transitive queries
  is to find all objects of a certain type that belong to a specific
  node.

  For instance, to find all antennas belonging to some node a client of the
  REST API can now use a get request like this::

    https://guifi-nodedb.funkfeuer.at/api/FFM-Antenna?AQ=belongs_to_node,EQ,374

  which returns all Antenna instances linked to Wireless_Interfaces connected
  to Net_Devices connected to the Node specified.

  Because ``FFM.Antenna`` is not directly connected to `FFM.Node`,
  multiple joins are necessary to find the node in question, resulting
  in a select statement looking like::

    SELECT
       ...
    FROM mom_id_entity
      JOIN ffm_antenna ON mom_id_entity.pid = ffm_antenna.pid
      JOIN ffm_wireless_interface_uses_antenna
        AS ffm_wireless_interface_uses_antenna_1
        ON ffm_wireless_interface_uses_antenna_1."right" = ffm_antenna.pid
      JOIN ffm_wireless_interface AS ffm_wireless_interface_1
        ON ffm_wireless_interface_1.pid
                = ffm_wireless_interface_uses_antenna_1."left"
      JOIN ffm_net_interface AS ffm_net_interface_1
        ON ffm_net_interface_1.pid = ffm_wireless_interface_1.pid
      JOIN ffm_net_device AS ffm_net_device_1
        ON ffm_net_device_1.pid = ffm_net_interface_1."left"
    WHERE ffm_net_device_1.node = 374

  To query Antenna instances belonging to a specific Person, the client would
  send a get-request like (domain elided)::

    /api/FFM-Antenna?AQ=belongs_to_node.owner,EQ,104

* Polymorphic queries computed by the database itself.

  Tapyr supports polymorphic attributes, i.e., attributes that refer to
  objects of a polymorphic type.

  By default, there is no database table for a partial type; a polymorphic
  attribute referring to such a type is a foreign key to one of the set of
  tables corresponding to the non-partial derived types.

  Queries for polymorphic types are now completely resolved by the
  relational database (previously, the results of several database queries
  needed to be combined in Python which was quite inefficient if sorting and
  limiting was involved).


Bibliography
------------

.. [nodedb13] `ff-nodedb.funkfeuer.at and guifi-nodedb.funkfeuer.at
    online`_, Aug 2013
.. _`ff-nodedb.funkfeuer.at and guifi-nodedb.funkfeuer.at online`:
    http://confine.funkfeuer.at/2013/08/ff-nodedb-funkfeuer-at-and-guifi-nodedb-funkfeuer-at-online-2/

.. [guifi1] `Guifi.net CNML Wiki`_, retrieved 2013-09-0
.. _`Guifi.net CNML Wiki`: http://en.wiki.guifi.net/wiki/CNML

.. [rsclib] `rsclib: Utility Routines`_, Ralf Schlatterbeck 2004-13
.. _`rsclib: Utility Routines`: http://rsclib.sourceforge.net/

.. [tanzer13] `Converter performance`_, Christian Tanzer Aug 2013
.. _`Converter performance`:
    http://confine.funkfeuer.at/2013/08/converter-performance/

.. [account] `Account migration`_, Christian Tanzer May 2013
.. _`Account migration`:
    http://confine.funkfeuer.at/2013/05/account-migration/

.. [cryptopan] `Crypto-PAn
    Cryptography-based  Prefix-preserving Anonymization`_
.. _`Crypto-PAn Cryptography-based  Prefix-preserving Anonymization`:
    http://www.cc.gatech.edu/computing/Telecomm/projects/cryptopan/

.. [pycryptopan] `A python implementation of Crypto-PAn a IP
    anonymization algorithm`_
.. _`A python implementation of Crypto-PAn a IP anonymization algorithm`:
    https://pypi.python.org/pypi/pycryptopan

.. [tapyr] `Tapyr Framework`_, 2012-13
.. _`Tapyr Framework`: https://github.com/Tapyr/tapyr

.. [pyspkac] `Support for Netscape / HTML5 SPKAC client certificate
    request`_
.. _`Support for Netscape / HTML5 SPKAC client certificate request`:
    https://pypi.python.org/pypi/pyspkac

.. [FFM] `Common Node Database`_, 2012-13
    (FIXME: Not yet referenced)
.. _`Common Node Database`: https://github.com/FFM/FFM
